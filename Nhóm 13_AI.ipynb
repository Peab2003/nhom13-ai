{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "DgU55eDWHdN0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106736,
     "status": "ok",
     "timestamp": 1718180287618,
     "user": {
      "displayName": "Dương Hoài Ngọc",
      "userId": "07243916879293064768"
     },
     "user_tz": -420
    },
    "id": "DgU55eDWHdN0",
    "outputId": "a8326b25-5b5d-42eb-d0d1-26d2b6cc1feb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (20231117)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numba in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai-whisper) (0.59.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai-whisper) (1.26.0)\n",
      "Requirement already satisfied: torch in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai-whisper) (2.3.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai-whisper) (4.66.4)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai-whisper) (10.2.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai-whisper) (0.7.0)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from numba->openai-whisper) (0.42.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken->openai-whisper) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken->openai-whisper) (2.31.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->openai-whisper) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->openai-whisper) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->openai-whisper) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->openai-whisper) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->openai-whisper) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->openai-whisper) (2024.6.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->openai-whisper) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->openai-whisper) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->openai-whisper) (2021.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch->openai-whisper) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "pip install -U openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "s0-pxEd0IBOE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7615,
     "status": "ok",
     "timestamp": 1718180800767,
     "user": {
      "displayName": "Dương Hoài Ngọc",
      "userId": "07243916879293064768"
     },
     "user_tz": -420
    },
    "id": "s0-pxEd0IBOE",
    "outputId": "a63cd84a-3c15-41a6-9803-c06f9f5dc7fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytube in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (15.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "wKzUKplv-LjG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14569,
     "status": "ok",
     "timestamp": 1718180817756,
     "user": {
      "displayName": "Dương Hoài Ngọc",
      "userId": "07243916879293064768"
     },
     "user_tz": -420
    },
    "id": "wKzUKplv-LjG",
    "outputId": "1cd1f3ca-8c96-4db8-f14b-aaeb5976d56c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hoang\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hebuofhpw2n4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 402,
     "status": "ok",
     "timestamp": 1718185867662,
     "user": {
      "displayName": "Dương Hoài Ngọc",
      "userId": "07243916879293064768"
     },
     "user_tz": -420
    },
    "id": "hebuofhpw2n4",
    "outputId": "938b2b4a-ef7c-4e1c-a197-ae11e04a73e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hoang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hoang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hoang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\hoang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import whisper\n",
    "from pytube import YouTube\n",
    "import datetime\n",
    "import tempfile\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "Ai0_PrUftTGB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51254,
     "status": "ok",
     "timestamp": 1718186027647,
     "user": {
      "displayName": "Dương Hoài Ngọc",
      "userId": "07243916879293064768"
     },
     "user_tz": -420
    },
    "id": "Ai0_PrUftTGB",
    "outputId": "897684a0-17ff-493d-81e0-5539d072e30a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hoang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video video.mp4 does not exist.\n",
      "\n",
      "YouTube video transcription:\n",
      "1 0:00:00 -- > 0:00:04 fuck way . 2 0:00:04 -- > 0:00:07 fuck ? 3 0:00:07 -- > 0:00:12 donate , five year ago , send mug , mug old 4 0:00:12 -- > 0:00:16 pee wear , say b , fucking apt . 5 0:00:16 -- > 0:00:19 yeah , always either prepare colonoscopy come back 6 0:00:19 -- > 0:00:20 colonoscopy . 7 0:00:20 -- > 0:00:22 fuck go ? 8 0:00:22 -- > 0:00:23 woodstock overassholes ! 9 0:00:23 -- > 0:00:26 damn , hate new stair ! 10 0:00:26 -- > 0:00:30 oh , , , fuck ! 11 0:00:30 -- > 0:00:31 fuck , get fuck ! 12 0:00:31 -- > 0:00:32 fuck , fuck ! 13 0:00:32 -- > 0:00:36 oh , god , disgusting , think gon na puke ! 14 0:00:36 -- > 0:00:37 fuck ! 15 0:00:37 -- > 0:00:42 peter , say volunteer shit ? 16 0:00:42 -- > 0:00:44 pretty sure heard people call spidey . 17 0:00:44 -- > 0:00:45 yeah , close friend . 18 0:00:45 -- > 0:00:46 name ? 19 0:00:46 -- > 0:00:47 peter ? 20 0:00:47 -- > 0:00:48 hey , pety , stuff . 21 0:00:48 -- > 0:00:49 oh , like . 22 0:00:49 -- > 0:00:50 yeah , like . 23 0:00:50 -- > 0:00:54 fat nobody , fuck spider-man , think feel ? 24 0:00:54 -- > 0:00:55 oh , god . 25 0:00:55 -- > 0:00:56 fucking plane . 26 0:00:56 -- > 0:00:58 say yesterday , stupid idiot ! 27 0:00:58 -- > 0:01:00 call criss , know . 28 0:01:00 -- > 0:01:01 fuck ! 29 0:01:01 -- > 0:01:02 shut , criss ! 30 0:01:02 -- > 0:01:06 , meg , suicide threat year chicken shit 31 0:01:06 -- > 0:01:07 rest u . 32 0:01:07 -- > 0:01:10 god , miraculous . 33 0:01:10 -- > 0:01:11 fuck . 34 0:01:11 -- > 0:01:15 hey , much stewie pay ? 35 0:01:15 -- > 0:01:17 4800 week ? 36 0:01:17 -- > 0:01:18 holy shit . 37 0:01:18 -- > 0:01:19 yeah . 38 0:01:19 -- > 0:01:21 continue play , little one . 39 0:01:21 -- > 0:01:22 future . 40 0:01:22 -- > 0:01:24 fuck talk ? 41 0:01:24 -- > 0:01:26 play write , see ? 42 0:01:26 -- > 0:01:29 goddamn fuck piece shit dick ! 43 0:01:29 -- > 0:01:31 tense bang 20 minute . 44 0:01:31 -- > 0:01:35 well , much chore ! 45 0:01:35 -- > 0:01:37 fuck go life ? 46 0:01:37 -- > 0:01:38 god , stewie , happen ? 47 0:01:38 -- > 0:01:40 fucking business , happen ? 48 0:01:40 -- > 0:01:44 , drive 900 fucking mile 14-year-old . 49 0:01:44 -- > 0:01:46 hardcore shit , right ? 50 0:01:46 -- > 0:01:50 like , part group kind fuck frank house every year . 51 0:01:50 -- > 0:01:52 big fucking liar ? 52 0:01:52 -- > 0:01:54 piece index ! 53 0:01:54 -- > 0:01:56 fuck cock , motherfucker ! 54 0:01:56 -- > 0:01:59 hey , fuck hour later ! 55 0:01:59 -- > 0:02:00 pfff ! 56 0:02:00 -- > 0:02:01 pfff ! 57 0:02:01 -- > 0:02:04 come , fuck horse . 58 0:02:04 -- > 0:02:06 oh , great spirit . 59 0:02:06 -- > 0:02:08 hold back situation ? 60 0:02:08 -- > 0:02:11 oh , fuck cock , second ground ! 61 0:02:11 -- > 0:02:12 pfff ! 62 0:02:12 -- > 0:02:13 motherfucker ! 63 0:02:13 -- > 0:02:14 get ! 64 0:02:14 -- > 0:02:15 kill ! 65 0:02:15 -- > 0:02:17 come back tomorrow , time . 66 0:02:17 -- > 0:02:19 get sad sunday . 67 0:02:19 -- > 0:02:21 fucking birthday , mikey ? 68 0:02:21 -- > 0:02:22 yeah ! 69 0:02:23 -- > 0:02:25 oh , fuck . 70 0:02:25 -- > 0:02:29 meg , say lip gloss unicorns chant tatum , something , something bullshit . 71 0:02:29 -- > 0:02:30 oh god ! 72 0:02:30 -- > 0:02:31 help ! 73 0:02:31 -- > 0:02:32 heart attack ! 74 0:02:32 -- > 0:02:36 anyone doctor ? 75 0:02:36 -- > 0:02:39 fucking way , someone doctor . 76 0:02:39 -- > 0:02:41 look u , fuck pig . 77 0:02:41 -- > 0:02:45 take juicy sweatpants dirty pillow home bucket coke 78 0:02:45 -- > 0:02:46 get hell sight . 79 0:02:46 -- > 0:02:48 sorry , mean waste time . 80 0:02:48 -- > 0:02:50 remember husband total chicken shit . 81 0:02:50 -- > 0:02:53 ryan , car , escape . 82 0:02:53 -- > 0:02:54 fuck say anything , okay ? 83 0:02:54 -- > 0:02:55 ! 84 0:02:55 -- > 0:02:57 fuck ? 85 0:02:57 -- > 0:02:59 yeah , yeah , think afraid ? 86 0:02:59 -- > 0:03:01 sleep back last night , piece shit .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tải mô hình Whisper\n",
    "model = whisper.load_model('base')\n",
    "\n",
    "def transcribe_video_to_text(file_path):\n",
    "    # Kiểm tra sự tồn tại của tệp\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f\"The video {file_path} does not exist.\")\n",
    "\n",
    "    # Chuyển đổi âm thanh thành văn bản\n",
    "    result = model.transcribe(file_path)\n",
    "\n",
    "    # Tạo một chuỗi để lưu kết quả\n",
    "    transcription = \"\"\n",
    "    for indx, segment in enumerate(result['segments']):\n",
    "        start_time = str(datetime.timedelta(seconds=int(segment['start'])))\n",
    "        end_time = str(datetime.timedelta(seconds=int(segment['end'])))\n",
    "        transcription += str(indx + 1) + '\\n'\n",
    "        transcription += start_time + ' --> ' + end_time + '\\n'\n",
    "        transcription += segment['text'] + '\\n\\n'\n",
    "\n",
    "    return transcription\n",
    "\n",
    "def download_youtube_audio_to_temp(youtube_link):\n",
    "    yt = YouTube(youtube_link)\n",
    "    stream = yt.streams.filter(only_audio=True).first()\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')\n",
    "    stream.download(filename=temp_file.name)\n",
    "    return temp_file.name\n",
    "\n",
    "def get_wordnet_pos(word_tag):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag_dict = {\n",
    "        \"J\": wordnet.ADJ,\n",
    "        \"N\": wordnet.NOUN,\n",
    "        \"V\": wordnet.VERB,\n",
    "        \"R\": wordnet.ADV\n",
    "    }\n",
    "    return tag_dict.get(word_tag[0].upper(), wordnet.NOUN)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Chuyển đổi văn bản thành chữ thường\n",
    "    text = text.lower()\n",
    "\n",
    "    # Loại bỏ các từ viết tắt thường gặp\n",
    "    abbreviations = {\n",
    "        r\"(\\w+)'s\": r\"\\1\",\n",
    "        r\"(\\w+)'m\": r\"\\1\",\n",
    "        r\"(\\w+)'ve\": r\"\\1\",\n",
    "        r\"(\\w+)'t\": r\"\\1\",\n",
    "        r\"(\\w+)'re\": r\"\\1\",\n",
    "        r\"(\\w+)'d\": r\"\\1\",\n",
    "        r\"(\\w+)'ll\": r\"\\1\",\n",
    "        r\"n't\": \"\",\n",
    "    }\n",
    "\n",
    "    for pattern, repl in abbreviations.items():\n",
    "        text = re.sub(pattern, repl, text)\n",
    "\n",
    "    # Tách từ và phân tích POS\n",
    "    words = word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "\n",
    "    # Loại bỏ stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word, tag in pos_tags if word not in stop_words]\n",
    "\n",
    "    # Chuẩn hóa từ về dạng gốc\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags if word not in stop_words]\n",
    "\n",
    "    # Kết hợp các từ thành văn bản mới\n",
    "    processed_text = ' '.join(words)\n",
    "\n",
    "    return processed_text\n",
    "\n",
    "# Tiền xử lý văn bản sau khi đã chuyển từ âm thanh\n",
    "def preprocess_transcribed_text(transcribed_text):\n",
    "    processed_text = preprocess_text(transcribed_text)\n",
    "    return processed_text\n",
    "\n",
    "def preprocess_and_save_transcription(transcription):\n",
    "    processed_text = preprocess_transcribed_text(transcription)\n",
    "\n",
    "    with open('processed_text.txt', 'w') as file:\n",
    "        file.write(processed_text)\n",
    "\n",
    "# Kết quả sau khi xử lý sẽ được lưu vào đây\n",
    "processed_transcription = \"\"\n",
    "\n",
    "# Sử dụng video cục bộ\n",
    "video_path = 'video.mp4'\n",
    "try:\n",
    "    local_transcription = transcribe_video_to_text(video_path)\n",
    "    processed_local_transcription = preprocess_transcribed_text(local_transcription)\n",
    "    processed_transcription += \"Local video transcription:\\n\"\n",
    "    processed_transcription += processed_local_transcription\n",
    "except FileNotFoundError as e:\n",
    "    processed_transcription += str(e) + \"\\n\"\n",
    "\n",
    "# Sử dụng link YouTube\n",
    "youtube_link = 'https://www.youtube.com/watch?v=LHVTHGtNeic'\n",
    "try:\n",
    "    temp_audio_file = download_youtube_audio_to_temp(youtube_link)\n",
    "    youtube_transcription = transcribe_video_to_text(temp_audio_file)\n",
    "    processed_youtube_transcription = preprocess_transcribed_text(youtube_transcription)\n",
    "    processed_transcription += \"\\nYouTube video transcription:\\n\"\n",
    "    processed_transcription += processed_youtube_transcription\n",
    "    os.remove(temp_audio_file)  # Xóa tệp tạm thời sau khi hoàn tất\n",
    "except FileNotFoundError as e:\n",
    "    processed_transcription += str(e) + \"\\n\"\n",
    "\n",
    "# In ra kết quả\n",
    "print(processed_transcription)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cfed5cf-842b-4203-821d-9ee262a5e316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video video.mp4 does not exist.\n",
      "\n",
      "YouTube video transcription:\n",
      "1 0:00:00 -- > 0:00:04 fuck way . 2 0:00:04 -- > 0:00:07 fuck ? 3 0:00:07 -- > 0:00:12 donate , five year ago , send mug , mug old 4 0:00:12 -- > 0:00:16 pee wear , say b , fucking apt . 5 0:00:16 -- > 0:00:19 yeah , always either prepare colonoscopy come back 6 0:00:19 -- > 0:00:20 colonoscopy . 7 0:00:20 -- > 0:00:22 fuck go ? 8 0:00:22 -- > 0:00:23 woodstock overassholes ! 9 0:00:23 -- > 0:00:26 damn , hate new stair ! 10 0:00:26 -- > 0:00:30 oh , , , fuck ! 11 0:00:30 -- > 0:00:31 fuck , get fuck ! 12 0:00:31 -- > 0:00:32 fuck , fuck ! 13 0:00:32 -- > 0:00:36 oh , god , disgusting , think gon na puke ! 14 0:00:36 -- > 0:00:37 fuck ! 15 0:00:37 -- > 0:00:42 peter , say volunteer shit ? 16 0:00:42 -- > 0:00:44 pretty sure heard people call spidey . 17 0:00:44 -- > 0:00:45 yeah , close friend . 18 0:00:45 -- > 0:00:46 name ? 19 0:00:46 -- > 0:00:47 peter ? 20 0:00:47 -- > 0:00:48 hey , pety , stuff . 21 0:00:48 -- > 0:00:49 oh , like . 22 0:00:49 -- > 0:00:50 yeah , like . 23 0:00:50 -- > 0:00:54 fat nobody , fuck spider-man , think feel ? 24 0:00:54 -- > 0:00:55 oh , god . 25 0:00:55 -- > 0:00:56 fucking plane . 26 0:00:56 -- > 0:00:58 say yesterday , stupid idiot ! 27 0:00:58 -- > 0:01:00 call criss , know . 28 0:01:00 -- > 0:01:01 fuck ! 29 0:01:01 -- > 0:01:02 shut , criss ! 30 0:01:02 -- > 0:01:06 , meg , suicide threat year chicken shit 31 0:01:06 -- > 0:01:07 rest u . 32 0:01:07 -- > 0:01:10 god , miraculous . 33 0:01:10 -- > 0:01:11 fuck . 34 0:01:11 -- > 0:01:15 hey , much stewie pay ? 35 0:01:15 -- > 0:01:17 4800 week ? 36 0:01:17 -- > 0:01:18 holy shit . 37 0:01:18 -- > 0:01:19 yeah . 38 0:01:19 -- > 0:01:21 continue play , little one . 39 0:01:21 -- > 0:01:22 future . 40 0:01:22 -- > 0:01:24 fuck talk ? 41 0:01:24 -- > 0:01:26 play write , see ? 42 0:01:26 -- > 0:01:29 goddamn fuck piece shit dick ! 43 0:01:29 -- > 0:01:31 tense bang 20 minute . 44 0:01:31 -- > 0:01:35 well , much chore ! 45 0:01:35 -- > 0:01:37 fuck go life ? 46 0:01:37 -- > 0:01:38 god , stewie , happen ? 47 0:01:38 -- > 0:01:40 fucking business , happen ? 48 0:01:40 -- > 0:01:44 , drive 900 fucking mile 14-year-old . 49 0:01:44 -- > 0:01:46 hardcore shit , right ? 50 0:01:46 -- > 0:01:50 like , part group kind fuck frank house every year . 51 0:01:50 -- > 0:01:52 big fucking liar ? 52 0:01:52 -- > 0:01:54 piece index ! 53 0:01:54 -- > 0:01:56 fuck cock , motherfucker ! 54 0:01:56 -- > 0:01:59 hey , fuck hour later ! 55 0:01:59 -- > 0:02:00 pfff ! 56 0:02:00 -- > 0:02:01 pfff ! 57 0:02:01 -- > 0:02:04 come , fuck horse . 58 0:02:04 -- > 0:02:06 oh , great spirit . 59 0:02:06 -- > 0:02:08 hold back situation ? 60 0:02:08 -- > 0:02:11 oh , fuck cock , second ground ! 61 0:02:11 -- > 0:02:12 pfff ! 62 0:02:12 -- > 0:02:13 motherfucker ! 63 0:02:13 -- > 0:02:14 get ! 64 0:02:14 -- > 0:02:15 kill ! 65 0:02:15 -- > 0:02:17 come back tomorrow , time . 66 0:02:17 -- > 0:02:19 get sad sunday . 67 0:02:19 -- > 0:02:21 fucking birthday , mikey ? 68 0:02:21 -- > 0:02:22 yeah ! 69 0:02:23 -- > 0:02:25 oh , fuck . 70 0:02:25 -- > 0:02:29 meg , say lip gloss unicorns chant tatum , something , something bullshit . 71 0:02:29 -- > 0:02:30 oh god ! 72 0:02:30 -- > 0:02:31 help ! 73 0:02:31 -- > 0:02:32 heart attack ! 74 0:02:32 -- > 0:02:36 anyone doctor ? 75 0:02:36 -- > 0:02:39 fucking way , someone doctor . 76 0:02:39 -- > 0:02:41 look u , fuck pig . 77 0:02:41 -- > 0:02:45 take juicy sweatpants dirty pillow home bucket coke 78 0:02:45 -- > 0:02:46 get hell sight . 79 0:02:46 -- > 0:02:48 sorry , mean waste time . 80 0:02:48 -- > 0:02:50 remember husband total chicken shit . 81 0:02:50 -- > 0:02:53 ryan , car , escape . 82 0:02:53 -- > 0:02:54 fuck say anything , okay ? 83 0:02:54 -- > 0:02:55 ! 84 0:02:55 -- > 0:02:57 fuck ? 85 0:02:57 -- > 0:02:59 yeah , yeah , think afraid ? 86 0:02:59 -- > 0:03:01 sleep back last night , piece shit .\n"
     ]
    }
   ],
   "source": [
    "#In văn bản đã được tiền xử lí\n",
    "print(processed_transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lqIRiF1z6aja",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1718181518562,
     "user": {
      "displayName": "Dương Hoài Ngọc",
      "userId": "07243916879293064768"
     },
     "user_tz": -420
    },
    "id": "lqIRiF1z6aja",
    "outputId": "058d8e41-1360-49cd-d588-eb79ff7d5005"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video video.mp4 does not exist. YouTube video transcription:\n",
      "1 0:00:00 -- > 0:00:04 fuck way .\n",
      "2 0:00:04 -- > 0:00:07 fuck ?\n",
      "3 0:00:07 -- > 0:00:12 donate , five year ago , send mug , mug old\n",
      "4 0:00:12 -- > 0:00:16 pee wear , say b , fucking apt .\n",
      "5 0:00:16 -- > 0:00:19 yeah , always either prepare colonoscopy come back\n",
      "6 0:00:19 -- > 0:00:20 colonoscopy .\n",
      "7 0:00:20 -- > 0:00:22 fuck go ?\n",
      "8 0:00:22 -- > 0:00:23 woodstock overassholes !\n",
      "9 0:00:23 -- > 0:00:26 damn , hate new stair !\n",
      "10 0:00:26 -- > 0:00:30 oh , , , fuck !\n",
      "11 0:00:30 -- > 0:00:31 fuck , get fuck !\n",
      "12 0:00:31 -- > 0:00:32 fuck , fuck !\n",
      "13 0:00:32 -- > 0:00:36 oh , god , disgusting , think gon na puke !\n",
      "14 0:00:36 -- > 0:00:37 fuck !\n",
      "15 0:00:37 -- > 0:00:42 peter , say volunteer shit ?\n",
      "16 0:00:42 -- > 0:00:44 pretty sure heard people call spidey .\n",
      "17 0:00:44 -- > 0:00:45 yeah , close friend .\n",
      "18 0:00:45 -- > 0:00:46 name ?\n",
      "19 0:00:46 -- > 0:00:47 peter ?\n",
      "20 0:00:47 -- > 0:00:48 hey , pety , stuff .\n",
      "21 0:00:48 -- > 0:00:49 oh , like .\n",
      "22 0:00:49 -- > 0:00:50 yeah , like .\n",
      "23 0:00:50 -- > 0:00:54 fat nobody , fuck spider-man , think feel ?\n",
      "24 0:00:54 -- > 0:00:55 oh , god .\n",
      "25 0:00:55 -- > 0:00:56 fucking plane .\n",
      "26 0:00:56 -- > 0:00:58 say yesterday , stupid idiot !\n",
      "27 0:00:58 -- > 0:01:00 call criss , know .\n",
      "28 0:01:00 -- > 0:01:01 fuck !\n",
      "29 0:01:01 -- > 0:01:02 shut , criss !\n",
      "30 0:01:02 -- > 0:01:06 , meg , suicide threat year chicken shit\n",
      "31 0:01:06 -- > 0:01:07 rest u .\n",
      "32 0:01:07 -- > 0:01:10 god , miraculous .\n",
      "33 0:01:10 -- > 0:01:11 fuck .\n",
      "34 0:01:11 -- > 0:01:15 hey , much stewie pay ?\n",
      "35 0:01:15 -- > 0:01:17 4800 week ?\n",
      "36 0:01:17 -- > 0:01:18 holy shit .\n",
      "37 0:01:18 -- > 0:01:19 yeah .\n",
      "38 0:01:19 -- > 0:01:21 continue play , little one .\n",
      "39 0:01:21 -- > 0:01:22 future .\n",
      "40 0:01:22 -- > 0:01:24 fuck talk ?\n",
      "41 0:01:24 -- > 0:01:26 play write , see ?\n",
      "42 0:01:26 -- > 0:01:29 goddamn fuck piece shit dick !\n",
      "43 0:01:29 -- > 0:01:31 tense bang 20 minute .\n",
      "44 0:01:31 -- > 0:01:35 well , much chore !\n",
      "45 0:01:35 -- > 0:01:37 fuck go life ?\n",
      "46 0:01:37 -- > 0:01:38 god , stewie , happen ?\n",
      "47 0:01:38 -- > 0:01:40 fucking business , happen ?\n",
      "48 0:01:40 -- > 0:01:44 , drive 900 fucking mile 14-year-old .\n",
      "49 0:01:44 -- > 0:01:46 hardcore shit , right ?\n",
      "50 0:01:46 -- > 0:01:50 like , part group kind fuck frank house every year .\n",
      "51 0:01:50 -- > 0:01:52 big fucking liar ?\n",
      "52 0:01:52 -- > 0:01:54 piece index !\n",
      "53 0:01:54 -- > 0:01:56 fuck cock , motherfucker !\n",
      "54 0:01:56 -- > 0:01:59 hey , fuck hour later !\n",
      "55 0:01:59 -- > 0:02:00 pfff !\n",
      "56 0:02:00 -- > 0:02:01 pfff !\n",
      "57 0:02:01 -- > 0:02:04 come , fuck horse .\n",
      "58 0:02:04 -- > 0:02:06 oh , great spirit .\n",
      "59 0:02:06 -- > 0:02:08 hold back situation ?\n",
      "60 0:02:08 -- > 0:02:11 oh , fuck cock , second ground !\n",
      "61 0:02:11 -- > 0:02:12 pfff !\n",
      "62 0:02:12 -- > 0:02:13 motherfucker !\n",
      "63 0:02:13 -- > 0:02:14 get !\n",
      "64 0:02:14 -- > 0:02:15 kill !\n",
      "65 0:02:15 -- > 0:02:17 come back tomorrow , time .\n",
      "66 0:02:17 -- > 0:02:19 get sad sunday .\n",
      "67 0:02:19 -- > 0:02:21 fucking birthday , mikey ?\n",
      "68 0:02:21 -- > 0:02:22 yeah !\n",
      "69 0:02:23 -- > 0:02:25 oh , fuck .\n",
      "70 0:02:25 -- > 0:02:29 meg , say lip gloss unicorns chant tatum , something , something bullshit .\n",
      "71 0:02:29 -- > 0:02:30 oh god !\n",
      "72 0:02:30 -- > 0:02:31 help !\n",
      "73 0:02:31 -- > 0:02:32 heart attack !\n",
      "74 0:02:32 -- > 0:02:36 anyone doctor ?\n",
      "75 0:02:36 -- > 0:02:39 fucking way , someone doctor .\n",
      "76 0:02:39 -- > 0:02:41 look u , fuck pig .\n",
      "77 0:02:41 -- > 0:02:45 take juicy sweatpants dirty pillow home bucket coke\n",
      "78 0:02:45 -- > 0:02:46 get hell sight .\n",
      "79 0:02:46 -- > 0:02:48 sorry , mean waste time .\n",
      "80 0:02:48 -- > 0:02:50 remember husband total chicken shit .\n",
      "81 0:02:50 -- > 0:02:53 ryan , car , escape .\n",
      "82 0:02:53 -- > 0:02:54 fuck say anything , okay ?\n",
      "83 0:02:54 -- > 0:02:55 !\n",
      "84 0:02:55 -- > 0:02:57 fuck ?\n",
      "85 0:02:57 -- > 0:02:59 yeah , yeah , think afraid ?\n",
      "86 0:02:59 -- > 0:03:01 sleep back last night , piece shit .\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Hàm tách đoạn văn thành các dòng dựa trên số thứ tự\n",
    "def split_lines_by_numbered_prefix(text):\n",
    "    lines = text.strip().split()\n",
    "    result = []\n",
    "    current_line = []\n",
    "    current_number = 1\n",
    "\n",
    "    for part in lines:\n",
    "        if part.isdigit() and int(part) == current_number:\n",
    "            if current_line:\n",
    "                result.append(' '.join(current_line))\n",
    "                current_line = []\n",
    "            current_line.append(part)\n",
    "            current_number += 1\n",
    "        else:\n",
    "            current_line.append(part)\n",
    "\n",
    "    if current_line:\n",
    "        result.append(' '.join(current_line))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Chia đoạn văn thành các dòng dựa trên số thứ tự\n",
    "split_lines = split_lines_by_numbered_prefix(processed_transcription)\n",
    "\n",
    "# Ghép các dòng lại thành chuỗi\n",
    "split_text = '\\n'.join(split_lines)\n",
    "\n",
    "# In nội dung đã tách dòng\n",
    "print(split_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f57a4f0-6d22-4b70-86cf-aee281db7b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_dict = {\n",
    "\"nội dung người lớn và các thuật ngữ tình dục\": [\"#freethenipple\", \"18+\", \"ampland\", \"anal\", \"anus\", \"arse\", \"ass\", \"asslick\", \"ball licking\", \"ball sucking\", \"bangbros\", \"bangbus\", \"banged\", \"barely legal\", \"bastinado\", \"bdsm\", \"bestiality\", \"bigtits\", \"bitch\", \"blow job\", \"blowjob\", \"blowjobs\", \"bondage\", \"boner\", \"boob\", \"boobies\", \"booboooooobs\", \"boobs\", \"bosomy\", \"bra\", \"brazzers\", \"buceta\", \"bukkake\", \"buttfuck\", \"butthole\", \"buttlick\", \"buttsex\", \"cam girl\", \"cameltoe\", \"censored\", \"clit\", \"clit licker\", \"clitoris\", \"clits\", \"cock\", \"cockhead\", \"cocksucker\", \"cocksuckers\", \"coom\", \"coomer\", \"cum\", \"cumguzzler\", \"cumming\", \"cumshot\", \"cumshots\", \"cumslut\", \"cunnilingus\", \"dildo\", \"dildos\", \"doggie style\", \"doggiestyle\", \"doggy style\", \"dominatrix\", \"dommes\", \"dry hump\", \"ecchi\", \"erotic\", \"erotica\", \"fetish\", \"fetishes\", \"fingered\", \"fingerfuck\", \"fingerfucked\", \"fingerfucks\", \"fingering\", \"fistfuck\", \"fistfucked\", \"fistfuckers\", \"fondle\", \"fondled\", \"footjob\", \"genital\", \"genitals\", \"girl on top\", \"gratis\", \"gratuit\", \"grope\", \"groped\", \"groping\", \"hand job\", \"handjob\", \"handjobs\", \"hardcoresex\", \"hem\", \"hentai\", \"horney\", \"horny\", \"hot\", \"hot carl\", \"hot sex\", \"hotbox\", \"hotsex\", \"hottest\", \"huge\", \"humping\", \"incest\", \"incl\", \"intercourse\", \"interracial\", \"invisible\", \"kalergi\", \"labia\", \"latex\", \"lesbians\", \"lezzie\", \"licking\", \"lolicon\", \"lolita\", \"masturbate\", \"masturbating\", \"masturbation\", \"masturbators\", \"milf\", \"milf hunter\", \"milfs\", \"nipple\", \"nipples\", \"nude\", \"nudes\", \"nudist\", \"nudity\", \"oral sex\", \"orgasim\", \"orgasm\", \"orgasms\", \"orgies\", \"orgy\", \"panties\", \"panty\", \"pantyhose\", \"penis\", \"pervert\", \"perverted\", \"perverts\", \"phonesex\", \"pingas\", \"porn\", \"pornhub\", \"porno\", \"pornography\", \"pornos\", \"prostitution\", \"pussies\", \"pussy\", \"pussylicking\", \"r18\", \"redhead\", \"reverse cowgirl\", \"rimjob\", \"rimming\", \"seksi\", \"semen\", \"sex\", \"sex work\", \"sex worker\", \"sexo\", \"sexual health\", \"sexually\", \"sexy\", \"sexy time\", \"shibari\", \"shoplifter\", \"slut\", \"sluts\", \"spycam\", \"squirt\", \"squirting\", \"strapon\", \"strip\", \"strip club\", \"stripper\", \"stripping\", \"succubus\", \"suck\", \"sucking\", \"teens\", \"thong\", \"threesome\", \"throating\", \"titfuck\", \"tities\", \"tits\", \"titten\", \"tittie\", \"titties\", \"titty\", \"topless\", \"tribadism\", \"twat\", \"twats\", \"undress\", \"undressing\", \"upskirt\", \"upskirts\", \"vagina\", \"vaginal\", \"vaginal thrush\", \"viagra\", \"voyeur\", \"vulva\", \"watch free\", \"watch online\", \"webcam\", \"x-rated\", \"xxx\", \"xxx-tentacion\"],\n",
    "\"thuyết âm mưu\": [\"pizzagate\", \"qanon\"],\n",
    "\"tội phạm và bạo lực\": [\"9-11\", \"9/11\", \"abuser\", \"abusing\", \"abusive\", \"accused\", \"adolescent\", \"allegation\", \"allegations\", \"assaulted\", \"boko haram\", \"bullying\", \"chester bennington\", \"columbine\", \"convicted\", \"crimes\", \"cruel\", \"dead body\", \"deaths\", \"el chapo\", \"elliot rodger\", \"epstein\", \"epstein didn't kill himself\", \"execution\", \"isil\", \"isis\", \"iyad el-baghdadi\", \"kidnap\", \"murder\", \"murdered\", \"punishments\", \"rape\", \"raped\", \"raping\", \"rapist\", \"robbery\", \"sandy hook\", \"slaughtering\", \"suspect\", \"ted bundy\", \"terrorism\", \"terrorist\", \"terrorists\", \"violence\", \"violently\", \"virginia tech shooting\", \"harass\", \"harassment\", \"hazing\", \"betting\", \"child pornography\", \"counterfeit\", \"gambling\", \"hacking\", \"pedophile\", \"snuff\"],\n",
    "\"ma túy và chất kích thích\": [\"cannabis\", \"cannabutter\", \"cocaine\", \"crack\", \"crackwhore\", \"drug\", \"drugs\", \"ecstasy\", \"hemp\", \"lsd\", \"marijuana\", \"meth\", \"pcp\", \"salvia\", \"stoned\", \"stoner\", \"thc\", \"vape\", \"weed\"],\n",
    "\"các tổ chức cực đoan\":[\"ku klux klan\", \"nazi\", \"neonazi\"],\n",
    "\"dịch bệnh và bệnh tật\":[\"coronavirus\", \"covid-19\", \"ebola\", \"aids\", \"bladder cancer\", \"breast cancer\", \"cancer\", \"cyst\", \"erectile dysfunction\", \"escherichia coli\", \"gallbladder cancer\", \"hiv\", \"lung cancer\", \"thyroid cancer\"],\n",
    "\"các vấn đề chính trị và xã hội\": [\"#metoo\", \"8chan\", \"abortion\", \"abortions\", \"al qaeda\", \"al qaida\", \"antifa\", \"blue anon\", \"democrat\", \"democratic\", \"democrats\", \"election\", \"election fraud\", \"elections\", \"electoral\", \"hunter biden\", \"pizzagate\", \"pro-choice\", \"qanon\", \"voter fraud\"],\n",
    "\"lời lẽ tục tĩu và xúc phạm\": [\"asshole\", \"assholes\", \"bitches\", \"blyat\", \"chuj\", \"cunt\", \"dick\", \"dickhead\", \"fack\", \"fag\", \"fagged\", \"faggit\", \"faghag\", \"fags\", \"fuck\", \"fuckboy\", \"fucked\", \"fucker\", \"fuckers\", \"fuckin\", \"fuckings\", \"fucks\", \"fucky\", \"fuk\", \"gayass\", \"gayfuck\", \"gaysex\", \"idiot\", \"im rick james bitch\", \"kurwa\", \"mothafucka\", \"mothafuckas\", \"mothafucker\", \"mothafuckers\", \"mothafucking\", \"motherfucka\", \"motherfucker\", \"motherfuckers\", \"motherfuckin\", \"motherfucking\", \"n1gga\", \"n1gger\", \"nasty\", \"nigga\", \"niggah\", \"niggas\", \"niggaz\", \"nip\", \"puta\", \"shit\", \"shite\", \"shitfuck\", \"shitpost\", \"shits\", \"shitted\", \"shitting\", \"shitty\", \"sonofabitch\", \"stfu\", \"whore\", \"whores\", \"yvonne\"],\n",
    "\"phân biệt chủng tộc và kỳ thị\": [\"chingada madre\", \"chink\", \"jews\", \"jigaboo\", \"jiggaboo\", \"kike\", \"nigger\", \"porch monkey\", \"porchmonkey\", \"racist\", \"white pride\", \"white supremacists\"],\n",
    "\"hành vi nguy hiểm và tự hại\": [\"anthony bourdain\", \"bulimia\", \"cut\", \"cutting\", \"eugenia cooney\", \"momo\", \"suicide\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac2d0a03-099b-4725-9dc9-734488d6cc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video video.mp4 does not exist. YouTube video transcription:\n",
      "1 0:00:00 -- > 0:00:04 fuck way .\n",
      "2 0:00:04 -- > 0:00:07 fuck ?\n",
      "3 0:00:07 -- > 0:00:12 donate , five year ago , send mug , mug old\n",
      "4 0:00:12 -- > 0:00:16 pee wear , say b , fucking apt .\n",
      "5 0:00:16 -- > 0:00:19 yeah , always either prepare colonoscopy come back\n",
      "6 0:00:19 -- > 0:00:20 colonoscopy .\n",
      "7 0:00:20 -- > 0:00:22 fuck go ?\n",
      "8 0:00:22 -- > 0:00:23 woodstock overassholes !\n",
      "9 0:00:23 -- > 0:00:26 damn , hate new stair !\n",
      "10 0:00:26 -- > 0:00:30 oh , , , fuck !\n",
      "11 0:00:30 -- > 0:00:31 fuck , get fuck !\n",
      "12 0:00:31 -- > 0:00:32 fuck , fuck !\n",
      "13 0:00:32 -- > 0:00:36 oh , god , disgusting , think gon na puke !\n",
      "14 0:00:36 -- > 0:00:37 fuck !\n",
      "15 0:00:37 -- > 0:00:42 peter , say volunteer shit ?\n",
      "16 0:00:42 -- > 0:00:44 pretty sure heard people call spidey .\n",
      "17 0:00:44 -- > 0:00:45 yeah , close friend .\n",
      "18 0:00:45 -- > 0:00:46 name ?\n",
      "19 0:00:46 -- > 0:00:47 peter ?\n",
      "20 0:00:47 -- > 0:00:48 hey , pety , stuff .\n",
      "21 0:00:48 -- > 0:00:49 oh , like .\n",
      "22 0:00:49 -- > 0:00:50 yeah , like .\n",
      "23 0:00:50 -- > 0:00:54 fat nobody , fuck spider-man , think feel ?\n",
      "24 0:00:54 -- > 0:00:55 oh , god .\n",
      "25 0:00:55 -- > 0:00:56 fucking plane .\n",
      "26 0:00:56 -- > 0:00:58 say yesterday , stupid idiot !\n",
      "27 0:00:58 -- > 0:01:00 call criss , know .\n",
      "28 0:01:00 -- > 0:01:01 fuck !\n",
      "29 0:01:01 -- > 0:01:02 shut , criss !\n",
      "30 0:01:02 -- > 0:01:06 , meg , suicide threat year chicken shit\n",
      "31 0:01:06 -- > 0:01:07 rest u .\n",
      "32 0:01:07 -- > 0:01:10 god , miraculous .\n",
      "33 0:01:10 -- > 0:01:11 fuck .\n",
      "34 0:01:11 -- > 0:01:15 hey , much stewie pay ?\n",
      "35 0:01:15 -- > 0:01:17 4800 week ?\n",
      "36 0:01:17 -- > 0:01:18 holy shit .\n",
      "37 0:01:18 -- > 0:01:19 yeah .\n",
      "38 0:01:19 -- > 0:01:21 continue play , little one .\n",
      "39 0:01:21 -- > 0:01:22 future .\n",
      "40 0:01:22 -- > 0:01:24 fuck talk ?\n",
      "41 0:01:24 -- > 0:01:26 play write , see ?\n",
      "42 0:01:26 -- > 0:01:29 goddamn fuck piece shit dick !\n",
      "43 0:01:29 -- > 0:01:31 tense bang 20 minute .\n",
      "44 0:01:31 -- > 0:01:35 well , much chore !\n",
      "45 0:01:35 -- > 0:01:37 fuck go life ?\n",
      "46 0:01:37 -- > 0:01:38 god , stewie , happen ?\n",
      "47 0:01:38 -- > 0:01:40 fucking business , happen ?\n",
      "48 0:01:40 -- > 0:01:44 , drive 900 fucking mile 14-year-old .\n",
      "49 0:01:44 -- > 0:01:46 hardcore shit , right ?\n",
      "50 0:01:46 -- > 0:01:50 like , part group kind fuck frank house every year .\n",
      "51 0:01:50 -- > 0:01:52 big fucking liar ?\n",
      "52 0:01:52 -- > 0:01:54 piece index !\n",
      "53 0:01:54 -- > 0:01:56 fuck cock , motherfucker !\n",
      "54 0:01:56 -- > 0:01:59 hey , fuck hour later !\n",
      "55 0:01:59 -- > 0:02:00 pfff !\n",
      "56 0:02:00 -- > 0:02:01 pfff !\n",
      "57 0:02:01 -- > 0:02:04 come , fuck horse .\n",
      "58 0:02:04 -- > 0:02:06 oh , great spirit .\n",
      "59 0:02:06 -- > 0:02:08 hold back situation ?\n",
      "60 0:02:08 -- > 0:02:11 oh , fuck cock , second ground !\n",
      "61 0:02:11 -- > 0:02:12 pfff !\n",
      "62 0:02:12 -- > 0:02:13 motherfucker !\n",
      "63 0:02:13 -- > 0:02:14 get !\n",
      "64 0:02:14 -- > 0:02:15 kill !\n",
      "65 0:02:15 -- > 0:02:17 come back tomorrow , time .\n",
      "66 0:02:17 -- > 0:02:19 get sad sunday .\n",
      "67 0:02:19 -- > 0:02:21 fucking birthday , mikey ?\n",
      "68 0:02:21 -- > 0:02:22 yeah !\n",
      "69 0:02:23 -- > 0:02:25 oh , fuck .\n",
      "70 0:02:25 -- > 0:02:29 meg , say lip gloss unicorns chant tatum , something , something bullshit .\n",
      "71 0:02:29 -- > 0:02:30 oh god !\n",
      "72 0:02:30 -- > 0:02:31 help !\n",
      "73 0:02:31 -- > 0:02:32 heart attack !\n",
      "74 0:02:32 -- > 0:02:36 anyone doctor ?\n",
      "75 0:02:36 -- > 0:02:39 fucking way , someone doctor .\n",
      "76 0:02:39 -- > 0:02:41 look u , fuck pig .\n",
      "77 0:02:41 -- > 0:02:45 take juicy sweatpants dirty pillow home bucket coke\n",
      "78 0:02:45 -- > 0:02:46 get hell sight .\n",
      "79 0:02:46 -- > 0:02:48 sorry , mean waste time .\n",
      "80 0:02:48 -- > 0:02:50 remember husband total chicken shit .\n",
      "81 0:02:50 -- > 0:02:53 ryan , car , escape .\n",
      "82 0:02:53 -- > 0:02:54 fuck say anything , okay ?\n",
      "83 0:02:54 -- > 0:02:55 !\n",
      "84 0:02:55 -- > 0:02:57 fuck ?\n",
      "85 0:02:57 -- > 0:02:59 yeah , yeah , think afraid ?\n",
      "86 0:02:59 -- > 0:03:01 sleep back last night , piece shit .\n"
     ]
    }
   ],
   "source": [
    "print (split_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49e6e60c-fa36-4fdc-a563-73c16d7ae07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:00:00 -- > 0:00:04\n",
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:00:04 -- > 0:00:07\n",
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:00:20 -- > 0:00:22\n",
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:00:26 -- > 0:00:30\n",
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:00:30 -- > 0:00:31\n",
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:00:31 -- > 0:00:32\n",
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:00:36 -- > 0:00:37\n",
      "Cụm từ 'shit' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:00:37 -- > 0:00:42\n",
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:00:50 -- > 0:00:54\n",
      "Cụm từ 'idiot' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:00:56 -- > 0:00:58\n",
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:01:00 -- > 0:01:01\n",
      "Cụm từ 'shit' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:01:02 -- > 0:01:06\n",
      "Cụm từ 'suicide' khớp với nhãn 'hành vi nguy hiểm và tự hại' tại thời gian 0:01:02 -- > 0:01:06\n",
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:01:10 -- > 0:01:11\n",
      "Cụm từ 'shit' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:01:17 -- > 0:01:18\n",
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:01:22 -- > 0:01:24\n",
      "Cụm từ 'dick' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:01:26 -- > 0:01:29\n",
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:01:26 -- > 0:01:29\n",
      "Cụm từ 'shit' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:01:26 -- > 0:01:29\n",
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:01:35 -- > 0:01:37\n",
      "Cụm từ 'shit' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:01:44 -- > 0:01:46\n",
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:01:46 -- > 0:01:50\n",
      "Cụm từ 'cock' khớp với nhãn 'nội dung người lớn và các thuật ngữ tình dục' tại thời gian 0:01:54 -- > 0:01:56\n",
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:01:54 -- > 0:01:56\n",
      "Cụm từ 'motherfucker' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:01:54 -- > 0:01:56\n",
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:01:56 -- > 0:01:59\n",
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:02:01 -- > 0:02:04\n",
      "Cụm từ 'cock' khớp với nhãn 'nội dung người lớn và các thuật ngữ tình dục' tại thời gian 0:02:08 -- > 0:02:11\n",
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:02:08 -- > 0:02:11\n",
      "Cụm từ 'motherfucker' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:02:12 -- > 0:02:13\n",
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:02:23 -- > 0:02:25\n",
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:02:39 -- > 0:02:41\n",
      "Cụm từ 'shit' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:02:48 -- > 0:02:50\n",
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:02:53 -- > 0:02:54\n",
      "Cụm từ 'fuck' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:02:55 -- > 0:02:57\n",
      "Cụm từ 'shit' khớp với nhãn 'lời lẽ tục tĩu và xúc phạm' tại thời gian 0:02:59 -- > 0:03:01\n",
      "Nhãn vi phạm: ['lời lẽ tục tĩu và xúc phạm', 'nội dung người lớn và các thuật ngữ tình dục', 'hành vi nguy hiểm và tự hại']\n",
      "Thời gian vi phạm: {'lời lẽ tục tĩu và xúc phạm': ['0:00:00 -- > 0:00:04', '0:00:04 -- > 0:00:07', '0:00:20 -- > 0:00:22', '0:00:26 -- > 0:00:30', '0:00:30 -- > 0:00:31', '0:00:31 -- > 0:00:32', '0:00:36 -- > 0:00:37', '0:00:37 -- > 0:00:42', '0:00:50 -- > 0:00:54', '0:00:56 -- > 0:00:58', '0:01:00 -- > 0:01:01', '0:01:02 -- > 0:01:06', '0:01:10 -- > 0:01:11', '0:01:17 -- > 0:01:18', '0:01:22 -- > 0:01:24', '0:01:26 -- > 0:01:29', '0:01:26 -- > 0:01:29', '0:01:26 -- > 0:01:29', '0:01:35 -- > 0:01:37', '0:01:44 -- > 0:01:46', '0:01:46 -- > 0:01:50', '0:01:54 -- > 0:01:56', '0:01:54 -- > 0:01:56', '0:01:56 -- > 0:01:59', '0:02:01 -- > 0:02:04', '0:02:08 -- > 0:02:11', '0:02:12 -- > 0:02:13', '0:02:23 -- > 0:02:25', '0:02:39 -- > 0:02:41', '0:02:48 -- > 0:02:50', '0:02:53 -- > 0:02:54', '0:02:55 -- > 0:02:57', '0:02:59 -- > 0:03:01'], 'hành vi nguy hiểm và tự hại': ['0:01:02 -- > 0:01:06'], 'nội dung người lớn và các thuật ngữ tình dục': ['0:01:54 -- > 0:01:56', '0:02:08 -- > 0:02:11']}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Hàm phân loại văn bản và tìm vị trí các từ vi phạm\n",
    "def classify_text_with_times(text, keyword_dict):\n",
    "    labels = set()  # Sử dụng set để tránh nhãn trùng lặp\n",
    "    time_positions = {}  # Từ điển để lưu trữ thời gian của các từ vi phạm\n",
    "\n",
    "    # Tách đoạn văn bản theo từng dòng\n",
    "    lines = text.strip().split(\"\\n\")\n",
    "\n",
    "    for line in lines:\n",
    "        if '-- >' in line:\n",
    "            parts = line.split(\"-- >\")\n",
    "            time_range = parts[0].strip().split()[1] + \" -- > \" + parts[1].strip().split()[0]\n",
    "            transcript = \" \".join(parts[1].strip().split()[1:])\n",
    "            cleaned_transcript = re.sub(r'[^\\w\\s]', '', transcript.lower())\n",
    "\n",
    "            for label, phrases in keyword_dict.items():\n",
    "                for phrase in phrases:\n",
    "                    escaped_phrase = re.escape(phrase)\n",
    "                    if re.search(r'\\b' + escaped_phrase + r'\\b', cleaned_transcript):\n",
    "                        labels.add(label)\n",
    "                        if label in time_positions:\n",
    "                            time_positions[label].append(time_range)\n",
    "                        else:\n",
    "                            time_positions[label] = [time_range]\n",
    "                        print(f\"Cụm từ '{phrase}' khớp với nhãn '{label}' tại thời gian {time_range}\")\n",
    "\n",
    "    return list(labels), time_positions\n",
    "# Phân loại đoạn văn bản và lấy thời gian các từ vi phạm\n",
    "labels, time_positions = classify_text_with_times(split_text, keyword_dict)\n",
    "print(\"Nhãn vi phạm:\", labels)\n",
    "print(\"Thời gian vi phạm:\", time_positions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5eb022-05ca-41b6-90d9-e446b766736a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24836f82-86e4-4f5e-bc6f-3134e0c556c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
